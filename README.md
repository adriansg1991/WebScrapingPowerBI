# ‚ÑπÔ∏è Power BI | Web scraping con Python
[![Python Version](https://img.shields.io/badge/python-3.8-blue)](https://www.python.org/downloads/release/python-380/)
[![Pandas](https://img.shields.io/badge/pandas-1.2.0+-yellow)](https://pandas.pydata.org/)
![Power BI](https://img.shields.io/badge/Power%20BI-Transforming%20Data%20into%20Insights-orange?style=flat&logo=power-bi)
![Requests](https://img.shields.io/badge/Requests-v2.26.0-blue)


<div id="header" align="center">
  <img src="https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExcm1tN3Zsdm81cjVjZTJscmExdmV2eTM3YmlkN2hzZHFhbDA2YXRmdCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9cw/Zebztgv7jmkoLe1DoY/giphy.gif" width="100"/>
</div>

## Introducci√≥n

Este proyecto implica la implementaci√≥n de web scraping mediante un sencillo script de Python en Power BI para extraer datos de una p√°gina web espec√≠fica. En este caso, el objetivo es importar un archivo .csv que ha sido cargado en una web directamente a Power BI y que se vaya actualizando autom√°ticamente sin necesidad de cambiar el origen de datos cada vez que se actualizen los datos en la web.

La automatizaci√≥n de este proceso resulta altamente beneficioso, ya que hay ocasiones en las que los datos del archivo subido en la p√°gina web se actualizan con frecuencia. Realizar esta tarea de manera manual implicar√≠a ajustar continuamente la ruta de origen y descargar el archivo .csv cada vez que se desee actualizar. Al aplicar esta soluci√≥n, Power BI se conectar√° directamente al origen de datos, eliminando la necesidad de llevar a cabo estos pasos manuales.

A continuaci√≥n, explicar√© como abord√© esta cas√∫istica mediante un breve script en Python, aprovechando las bibliotecas Pandas y requests.
<div id="header" align="center">
  <img src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*DKnPHPUBOuSV50E6Rq0vyQ.png" width="800"/>
</div>

---
## üì¶Librer√≠as utilizadas
- Pandas
- Requests
  
---

### *CONSEJO*:

Antes de realizar el script directamente en Power BI, aconsejo realizarlo en el editor de c√≥digo que utilices, VSCode, Pycharm, Jupyter Notebook, etc.

De esta forma, te puedes asegurar que funcione correctamente viendo el resultado final, adem√°s de ver posibles errores en el c√≥digo. Posteriormente, solo basta con pegar el c√≥digo en Power BI.
<p align="center">
  <img src="https://github.com/adriansg1991/WebScrapingPowerBI/blob/main/WS1.png" alt="Script">
</p>

Como pod√©is ver, primero uso mi editor de c√≥digo para importar el .csv de la web e importar √∫nicamente las columnas que necesito para el an√°lisis. Una vez veo el resultado final con el m√©todo .head (para poder ver los primeros registros).
De esta forma, me aseguro que el output final contenga la informaci√≥n que quiero. Por tanto, unicamente queda pegar el script en Power BI.
<p align="center">
  <img src="https://github.com/adriansg1991/WebScrapingPowerBI/blob/main/WS2.png" alt="ScriptPowerBI">
</p>

Adem√°s, aconsejo instalar la librer√≠a requests, para verificar si es posible importar datos de la web haciendo la petici√≥n al servidor.
<p align="center">
  <img src="https://github.com/adriansg1991/WebScrapingPowerBI/blob/main/WS3.png" alt="Request">
</p>


```python
import requests

response = requests.get('https://opendata-ajuntament.barcelona.cat/data/dataset/29d1b774-a83e-4c1e-91f7-1b9ad042ea83/resource/87a8aeda-d3eb-4ba5-bcad-b9ab0c296df5/download/2022_accidents_causa_conductor_gu_bcn_.csv')

print(response.status_code)
200 # OK
``` 

Usamos la librer√≠a request con el m√©todo get para preguntarle al servidor si podemos solicitar informaci√≥n o recursos concretos de la web.
Si el c√≥digo de respuesta es 200, significa que puedes importar la informaci√≥n.

En algunas webs no es posible importar informaci√≥n. Existen diferentes respuestas que te puede devolver requests.get:

- **1xx**: Informativo ‚Äî Solicitud recibida, proceso continuo.
- **2xx: Success ‚Äî La acci√≥n fue recibida, entendida y aceptada con √©xito.**
- **3xx**: Redirecci√≥n ‚Äî Se deben tomar medidas adicionales para completar la solicitud.
- **4xx**: Error de cliente: la solicitud contiene una sintaxis incorrecta o no se puede cumplir.
- **5xx**: Error de servidor ‚Äî El servidor no pudo cumplir con una solicitud aparentemente v√°lida.

---
## Web Scrapping
Se trata de un procedimiento utilizado para extraer datos de sitios web mediante el uso del lenguaje de programaci√≥n Python, con el objetivo de conectar la extracci√≥n directamente a Power BI.

Para llevar a cabo este proceso, es esencial contar con Python instalado en nuestros equipos y especificar la ruta de instalaci√≥n en la aplicaci√≥n Power BI. Esto permitir√° establecer la conexi√≥n necesaria entre la extracci√≥n de datos mediante Python y la integraci√≥n fluida con Power BI. La instalaci√≥n adecuada de Python y la configuraci√≥n precisa de la ruta son pasos cruciales para garantizar el funcionamiento eficiente de esta conexi√≥n.

## Desarrollo
(foto)
En ocasiones, surge la necesidad de descargar archivos peri√≥dicamente desde una p√°gina web y posteriormente reemplazar los archivos existentes con la versi√≥n m√°s reciente.
El siguiente ejercicio busca simular la interacci√≥n humana al descargar un archivo CSV desde un sitio web espec√≠fico. Se logra mediante un peque√±o script en Power BI, que automatiza este proceso.
Para este prop√≥sito, he empleado un conjunto de datos de la p√°gina Open Data del Ajuntament de Barcelona. Este conjunto de datos proporciona informaci√≥n sobre los accidentes gestionados por la Gu√†rdia Urbana en Barcelona, clasificados por causa.
A continuaci√≥n, presento un script b√°sico en Power BI para llevar a cabo esta tarea:
import pandas as pd

```python
url = 'https://opendata-ajuntament.barcelona.cat/data/dataset/29d1b774-a83e-4c1e-91f7-1b9ad042ea83/resource/87a8aeda-d3eb-4ba5-bcad-b9ab0c296df5/download/2022_accidents_causa_conductor_gu_bcn_.csv'

AccidentsBCN2022 = pd.read_csv(url)

columns_ok = ['Nom_districte','Nom_barri','Nom_carrer','Descripcio_dia_setmana','NK_Any','Mes_any','Nom_mes','Dia_mes','Hora_dia','Descripcio_causa_mediata','Descripcio_torn']
AccidentsBCN2022 = AccidentsBCN2022[columns_ok]
```
(foto)

Podemos usar Pandas para Data cleaning & Data Wrangling. Por ejemplo, eliminar nulos e importar √∫nicamente las columnas que nos importan. De esta manera, la importaci√≥n ser√° m√°s eficiente y ocupar√° menos espacio.

## Datasets
Lo pod√©is consultar en el siguiente link:
*https://opendata-ajuntament.barcelona.cat/data/es/dataset/accidents_causa_conductor_gu_bcn*

## Resultado final
<div id="header" align="center">
  <img src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*juD-r5hPdEMEK5R_DP1KQA.gif" width="850"/>
</div>

Ya hemos establecido la conexi√≥n entre Power BI y la fuente de datos, lo que significa que cualquier cambio en el archivo cargado en la web se reflejar√° autom√°ticamente en el dashboard.
Simplemente actualizando la informaci√≥n en Power BI, podemos mantener el dashboard actualizado sin la necesidad de modificar el origen de datos.

### Requisitos
Instalar Python.
Instalar las librer√≠as ‚Äúrequests‚Äù y‚Äúpandas‚Äù.
Instalar Power BI.
Generar Script de Python en Power BI para obtener el enlace correcto y ejecutarlo.
---
En lugar de utilizar un programa de visualizaci√≥n de datos como Power BI, tambi√©n podemos aprovechar librer√≠as de Python como Matplotlib o Seaborn para crear gr√°ficos. Aunque esta opci√≥n puede ser m√°s compleja, si lo comparamos con Power BI, proporciona un mayor control sobre la personalizaci√≥n de las visualizaciones.
---

Si tienes alguna pregunta o sugerencia, no dudes en contactarme a trav√©s de mi correo electr√≥nico o en Linkedin.

¬°Gracias por visitar el repositorio! üöÄ
